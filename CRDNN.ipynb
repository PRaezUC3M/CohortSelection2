{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRaezUC3M/CohortSelection2/blob/master/CRDNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TQR9Sn1usb-x",
        "outputId": "b7840320-ab10-418a-9259-8f27b3c8a23b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GvstijeTsb-6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(1)\n",
        "tf.set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vluB44afpEHL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Configurartion of the experiments**\n",
        "The different possible experiments have been automated. It is inspired in grid-search, and the parameters must be expressed in array-like style. You can find an example below.\n",
        "\n",
        "Every possible example will be generated from the combination of the different parameters given."
      ]
    },
    {
      "metadata": {
        "id": "AdJIJMn1pbCa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "load_embeddings = [True]\n",
        "num_classes = [None]\n",
        "embeddings_size = [None]\n",
        "rnn_size = [[64]]\n",
        "cell_type = [\"GRU\"]\n",
        "bidirectional = [True]\n",
        "attention = [False]\n",
        "dropout = [0.3]\n",
        "dnn_size = [[32]]\n",
        "batch_size = [None]\n",
        "\n",
        "indexes = [\"load_embeddings\", \"num_classes\", \"embeddings_size\", \"rnn_size\", \"cell_type\", \"bidirectional\", \"attention\", \"dropout\", \"dnn_size\", \"batch_size\"]\n",
        "param   = [tfidf, load_embeddings, num_classes, embeddings_size, rnn_size, cell_type, bidirectional, attention, dropout, dnn_size, batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b65TBRSg3wep",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def combine_params(param, indexes):\n",
        "  combinations = list(itertools.product(*param))\n",
        "  param_combinations = [{k:v for k, v in zip(indexes, combination)}  for combination in combinations]\n",
        "  for p in param_combinations:\n",
        "    # The embeddings size must adapt to the embeddings loaded.\n",
        "    if p[\"load_embeddings\"]:\n",
        "      p[\"embeddings_size\"] = None\n",
        "  return param_combinations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N-nFuYPyy8eW",
        "colab_type": "code",
        "outputId": "7e58ea0b-c30a-472d-9766-a99f4a2e69e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "cell_type": "code",
      "source": [
        "network_parameters = combine_params(param, indexes)\n",
        "network_parameters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'attention': False,\n",
              "  'batch_size': None,\n",
              "  'bidirectional': True,\n",
              "  'cell_type': 'GRU',\n",
              "  'dnn_size': [32],\n",
              "  'dropout': 0.3,\n",
              "  'embeddings_size': None,\n",
              "  'load_embeddings': True,\n",
              "  'num_classes': None,\n",
              "  'rnn_size': [64]}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-U6xgKq_sb_B"
      },
      "cell_type": "markdown",
      "source": [
        "# **Load the train and test csv files**\n",
        "This functions load the data and generate the different datasets from the given csv files. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UruHey_Zsb_C",
        "outputId": "e45bf1ae-9b6d-4edd-99b0-0d87f8ab7b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "SST_HOME='drive/My Drive/Colab Notebooks/CohortSelection2/'\n",
        "path_train=SST_HOME+'data/train/train.csv'\n",
        "path_test=SST_HOME+'data/test/test.csv'\n",
        "\n",
        "def load(path):\n",
        "  \n",
        "  df = pd.read_csv(path,header=0, delimiter=\"\\t\", quoting=3)\n",
        "\n",
        "  categories=df.columns[2:]\n",
        "  idFiles = df[['IDFILE']].as_matrix().tolist()\n",
        "\n",
        "  texts = df[['TEXT']].as_matrix()\n",
        "  X = [x[0].strip() for x in texts.tolist()]\n",
        "\n",
        "  #we only keep the columns with the categories.\n",
        "  Y = df.drop(['IDFILE', 'TEXT'], axis=1).as_matrix()\n",
        "\n",
        "\n",
        "  print(path,'dataset loaded')\n",
        "  \n",
        "  return X, Y, categories, idFiles\n",
        "\n",
        "\n",
        "train_x, train_y, CATEGORIES, _ = load(path_train)\n",
        "test_x, test_y, _, IDFILES = load(path_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/My Drive/Colab Notebooks/CohortSelection2/data/train/train.csv dataset loaded\n",
            "drive/My Drive/Colab Notebooks/CohortSelection2/data/test/test.csv dataset loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VvG0svi8QAER",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for p in network_parameters:\n",
        "  p[\"num_classes\"] = train_y.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zswqSRmTqM2A"
      },
      "cell_type": "markdown",
      "source": [
        "#**Balancing the categories**\n",
        "We can see that there are some categories way more present than others in our dataset. Let's sort them."
      ]
    },
    {
      "metadata": {
        "id": "OXBDCgcT8c5Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The categories are distributed in the following way\n"
      ]
    },
    {
      "metadata": {
        "id": "R9zxnXt38hO-",
        "colab_type": "code",
        "outputId": "e6bae78a-30db-47d3-af11-8b6eece2d2da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  \n",
        "\n",
        "fig = plt.figure(figsize=(20,8))\n",
        "(ax_train, ax_test) = fig.subplots(ncols=2, nrows=1)\n",
        "g1 = sns.barplot(x=train_y.sum(axis=0), y=CATEGORIES, ax=ax_train)\n",
        "ax_train.set_xlabel('Number of records')\n",
        "g2 = sns.barplot(x=test_y.sum(axis=0), y=CATEGORIES, ax=ax_test)\n",
        "ax_test.set_xlabel('Number of records')\n",
        "g1.set_title(\"Criteria distribution on training dataset\")\n",
        "g2.set_title(\"Criteria distribution on testing dataset\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  stat_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Criteria distribution on testing dataset')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABM8AAAHvCAYAAABDg/hfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA9pzREYE64/AAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7Bfd-GpbqM2G"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can see the differences in a easier way, we will add weights to the different classes, based on how present they are in the dataset."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wQaO6I_tqM2H",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes = np.add(sum(train_y), sum(test_y))\n",
        "total_cases = sum(classes)\n",
        "class_weight = [1 / (c/total_cases) for c in classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Pvixevcqsb_Z"
      },
      "cell_type": "markdown",
      "source": [
        "# **Tokenize the dataset and use the word embeddings**\n",
        "\n",
        "This shows the set of different words ordered by frequency. *tokenizer.word_index*\n",
        "\n",
        "The text is tokenized and cleaned of stop-words as well as punctuation signs. Also the numbers are substituted by a token \"nmbr\"\n",
        "\n",
        "We crop the beggining of the examples because it is the date when they\n",
        "were written down.\n",
        "\n",
        "Finally, and after being tokenized, the different sentences are padded to match the maximum length.\n",
        "\n",
        "max_length == 7813 it is really a huge vector because we have to pad\n",
        "it afterwards, in order to get it into the CNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t3ntmzICsb_a",
        "outputId": "7ae4e119-10c6-4bbf-cc46-0bfb76c689f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words=stopwords.words('english')\n",
        "# Define vocabulary length\n",
        "MAX_WORDS = 5000\n",
        "# Defined from the dataset itself.\n",
        "DATE_LENGTH = 23"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lV3LXEEgsb_h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We are using this function to clean the test set\n",
        "def tokenize_clean_text(text, tokenizer=None, max_length=None, max_words=MAX_WORDS, date_length=DATE_LENGTH):\n",
        "  \"\"\"\n",
        "  This function is in charge of tokenizing the text it is given. It also cleans\n",
        "  the text from stop-words, punctuation, and gives a special token to numbers.\n",
        "  \n",
        "  :param text: The texts to tokenize in a bidimensional python array.\n",
        "  \n",
        "  :returns: The tokenized and cleaned text in a bidimensional python array.\n",
        "            The tokenizer used to preprocess the text.\n",
        "            The maximum length used for padding.\n",
        "  \"\"\"   \n",
        "  # Consider to stemm or lemmatize the text \n",
        "  \n",
        "  cropped_date_text = [sentence[date_length:] for sentence in text]\n",
        "    \n",
        "  # We remove the numbers\n",
        "  cropped_date_numbers_text = [\" \".join([word if not word.isdigit() else \"\"\n",
        "                                for word in sentence.split()])\n",
        "                               for sentence in cropped_date_text]\n",
        "  \n",
        "  # Delete stopwords as well as every word less than 3 chars.\n",
        "  cropped_date_numbers_stopw_text = [\" \".join([word if not (word in stop_words or len(word) <= 3) else \"\"\n",
        "                                      for word in sentence.split()])\n",
        "                                     for sentence in cropped_date_numbers_text]\n",
        "  \n",
        "  vec = TfidfVectorizer(max_features=max_words)\n",
        "  tfidf_mat = vec.fit_transform(cropped_date_numbers_stopw_text).toarray()\n",
        "  tfid_words = vec.get_feature_names()\n",
        "  \n",
        "  cropped_date_numbers_stopw_tfidf_text = [\" \".join([word if word in tfid_words else \"\"\n",
        "                                          for word in sentence.split()])\n",
        "                                          for sentence in cropped_date_numbers_stopw_text]\n",
        "  \n",
        "  if tokenizer is None:\n",
        "    tokenizer = Tokenizer(num_words=max_words) # They use 5k words too\n",
        "    tokenizer.fit_on_texts(cropped_date_numbers_stopw_tfidf_text)\n",
        "  # We tokenize the sentences\n",
        "  tokenized_text = tokenizer.texts_to_sequences(cropped_date_numbers_stopw_tfidf_text)\n",
        "  \n",
        "  if max_length == None:\n",
        "    max_length = 0\n",
        "    for sentence in tokenized_text:\n",
        "      max_length = max_length if len(sentence) < max_length else len(sentence)\n",
        "  \n",
        "  # Now we return the padded the sequences.\n",
        "  return pad_sequences(tokenized_text, max_length), tokenizer, max_length, cropped_date_numbers_stopw_tfidf_text, cropped_date_numbers_stopw_text\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "aTQ39hlAqM2d"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN Input\n",
        "\n",
        "Here we take a maximum length of file by obtaining the accumulative density distribution of the training examples. This way we can see how many examples fall under certain threshold. Which will be fixed to 80% of the total examples. This length is 5000 words roughly."
      ]
    },
    {
      "metadata": {
        "id": "JEszPNw7n2si",
        "colab_type": "code",
        "outputId": "5013350c-9303-4bb8-926a-c28d6624885f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "cell_type": "code",
      "source": [
        "train_x_token, tokenizer, max_length, tfidf_text, clean_text = tokenize_clean_text(train_x)\n",
        "  \n",
        "test_x_token, _, _, _, _ = tokenize_clean_text(test_x, tokenizer, max_length=max_length)\n",
        "assert len(train_x_token) == len(train_x)\n",
        "assert len(test_x_token) == len(test_x)\n",
        "\n",
        "lenghts = [len(sentence[DATE_LENGTH:].split(\" \")) for sentence in tfidf_text]\n",
        "plt.hist(lenghts, cumulative=True, color='r')\n",
        "\n",
        "lenghts = [len(sentence[DATE_LENGTH:].split(\" \")) for sentence in clean_text]\n",
        "plt.hist(lenghts, cumulative=True, color='b')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 17.,  53., 113., 158., 181., 194., 197., 200., 201., 202.]),\n",
              " array([ 793. , 1380.7, 1968.4, 2556.1, 3143.8, 3731.5, 4319.2, 4906.9,\n",
              "        5494.6, 6082.3, 6670. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAYgCADAGAAggwAgAEIMgAABvhfp57y0mCJSucAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "S4ag7fBnxTbo",
        "colab_type": "code",
        "outputId": "5b90aca9-5e39-46db-95c0-14892f4a7c14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "if len(tokenizer.word_index) < MAX_WORDS:\n",
        "  MAX_WORDS = len(tokenizer.word_index)\n",
        "  print(MAX_WORDS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bNyihoeLqM2h",
        "outputId": "27f9b45e-dee6-43d7-ee3a-4260e64e8b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(max_length)\n",
        "# Thus, we initialize the maximum word length as\n",
        "for p in network_parameters:\n",
        "  p[\"max_length\"] = max_length"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "t_XzzFpUqM2o"
      },
      "cell_type": "markdown",
      "source": [
        "# **TensorBoard**\n",
        "TensorBoard is a great tool for DL visualization. It shows the evolution of metrics during the training phase, as well as the weights, distributions, and even the graph of the neural net. \n",
        "\n",
        "We will be using tensorboardcolab in order to run a \n",
        "TensorBoard instance. This will initialize a ngrok machine and launch TensorBoard for us to see. \n",
        "\n",
        "TensorBoard will be accesible by the url "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Sbcq5gOMqM2p",
        "outputId": "0871c929-2679-4a44-f610-b8bfe3e690e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# We install tensorboard colab in case we don't have it already.\n",
        "!pip install tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "79ivurQUqM2t",
        "outputId": "0d763db7-0a59-41f0-91ef-2fb50f1f63e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorboardcolab as tb\n",
        "\n",
        "tbc=tb.TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://623ca31c.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Gyam03X6qM2x"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the embeddings\n",
        "\n",
        "In this step, we load the word embeddings from the wikipedia, pubmed and PMC. Then we filter them adapting to the words we have in our dataset. This is, if the word appears in the pubmed we take its weights, which are set to 0 otherwise."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SJO1m5MwqM2y",
        "outputId": "b69b32a7-e86d-489a-d5f8-a6f4eac98a2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "cell_type": "code",
      "source": [
        "# seemingly gensim is not installed in google colab\n",
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.92)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.92 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.92)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.92->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.92->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zJsmyAUOqM20",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "PATH_W2V = SST_HOME + \"DL/w2v/wikipedia-pubmed-and-PMC-w2v.bin\"\n",
        "PATH_W2V = SST_HOME + \"DL/w2v/svd_300.txt\"\n",
        "# PATH_W2V = SST_HOME + \"DL/w2v/IDX_IPR_C_N_L_month_ALL_MEMBERS_fold1_s300_w20_ss5_hs_thr12.txt\"\n",
        "# PATH_W2V = SST_HOME + \"DL/w2v/DeVine_etal_200.txt\"\n",
        "\n",
        "PATH_CUID = SST_HOME + \"DL/w2v/CUID/2b_concept_ID_to_CUI.txt\"\n",
        "PATH_STRD = SST_HOME + \"DL/w2v/CUID/2a_concept_ID_to_string.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJdcpbm7_tMh",
        "colab_type": "code",
        "outputId": "0cd529aa-1724-4e86-f4db-856042b7a2f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "print(listdir(SST_HOME + \"DL/w2v\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['wikipedia-pubmed-and-PMC-w2v.bin', 'DeVine_etal_200.txt', 'svd_300.txt', 'CUID', 'IDX_IPR_C_N_L_month_ALL_MEMBERS_fold1_s300_w20_ss5_hs_thr12.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "81mK3tCEqM22",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def text_to_dict(path, reverse=False):\n",
        "  d = {}\n",
        "  with open(path, encoding='latin-1') as f:\n",
        "      for line in f:\n",
        "        if reverse:\n",
        "          val = line.split()[0]\n",
        "          key = \"\".join(line.split()[1:])\n",
        "        else:\n",
        "          key = line.split()[0]\n",
        "          val = \"\".join(line.split()[1:])\n",
        "          \n",
        "        d[key] = val\n",
        "  return d\n",
        "        \n",
        "def load_W2V_model(path):\n",
        "    model = KeyedVectors.load_word2vec_format(path, binary=True if path[-3:]==\"bin\" else False)\n",
        "    print(\"Loaded W2V model\")\n",
        "    return model\n",
        "  \n",
        "def generate_embedding_weigths(word_index, max_words, model, binary=False):\n",
        "  embedding_matrix = np.zeros((max_words, model.vector_size), dtype=np.float32)\n",
        "  d_cuid = text_to_dict(PATH_CUID)\n",
        "  d_str = text_to_dict(PATH_STRD, reverse=True)\n",
        "  hit = 0\n",
        "  for word, i in word_index.items():\n",
        "    if i >= max_words:\n",
        "        break\n",
        "    if not binary:\n",
        "      try:\n",
        "        word = d_cuid[d_str[word]]  # Un-comment if using CUIDS\n",
        "        # word =  d_str[word]  # Un-comment if using concept ids\n",
        "      except KeyError:\n",
        "        continue\n",
        "    if word in model:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = model[word]\n",
        "        hit += 1\n",
        "  print(\"Hits: {}\\nTotal: {}\".format(hit, i))\n",
        "\n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6qPp111eqM26",
        "outputId": "924d1058-2b69-460b-bf75-f7778ec28b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "if any([p[\"load_embeddings\"] for p in network_parameters]):\n",
        "  if not 'model' in locals():\n",
        "    model = load_W2V_model(PATH_W2V)\n",
        "  # Generate the weights matrix\n",
        "  embedding_matrix = generate_embedding_weigths(tokenizer.word_index, MAX_WORDS, model)\n",
        "  for p in network_parameters:\n",
        "    if p[\"load_embeddings\"]: \n",
        "      p[\"embeddings_size\"] = model.vector_size\n",
        "      p[\"embedding_matrix\"] = embedding_matrix\n",
        "    else:\n",
        "      p[\"embedding_matrix\"] = None\n",
        "      \n",
        "else:\n",
        "  for p in network_parameters:\n",
        "    p[\"embedding_matrix\"] = None"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded W2V model\n",
            "Hits: 0\n",
            "Total: 4348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TOc6GfiVtFVh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create a keras Embedding model**\n",
        "\n",
        "In this section we will create a Keras RNN model, compile, and train it.\n",
        "\n",
        "In this model we can decide to generate the different embeddings for the words by using a pre-trained embeddings as the wikipedia ones for example.\n",
        "\n",
        "Some information about the architecture of the net is shown bellow. "
      ]
    },
    {
      "metadata": {
        "id": "vVaH2QqctjPJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Activation, Embedding, Dropout, Input\n",
        "from keras.layers import Lambda, Flatten, RepeatVector, Permute, Multiply\n",
        "from keras.layers import LSTM, GRU, Bidirectional, BatchNormalization\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import RMSprop, Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dmQoMtHYsT5s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cell_type = {\"LSTM\": LSTM,\n",
        "             \"GRU\": GRU}\n",
        "\n",
        "for p in network_parameters:\n",
        "  p[\"cell_type\"] = cell_type[p[\"cell_type\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xvQjbZlBSEUP",
        "colab_type": "code",
        "outputId": "0d69f53c-5dc3-4fe4-f27e-c188edc86244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "cell_type": "code",
      "source": [
        "network_parameters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'attention': False,\n",
              "  'batch_size': None,\n",
              "  'bidirectional': True,\n",
              "  'cell_type': keras.layers.recurrent.GRU,\n",
              "  'dnn_size': [32],\n",
              "  'dropout': 0.3,\n",
              "  'embedding_matrix': array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  'embeddings_size': 300,\n",
              "  'load_embeddings': True,\n",
              "  'max_length': 2336,\n",
              "  'num_classes': 13,\n",
              "  'rnn_size': [64]}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "_RChdTccu23y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_embeddings(z, load, size, embedding_matrix):\n",
        "  \"\"\"\n",
        "  This method adds embeddings to the network.\n",
        "  \n",
        "  Returns the net with the embeddings added.\n",
        "  \"\"\"\n",
        "  if load:\n",
        "    #TODO\n",
        "    # remove MAX_WORDS and pass it as a parameter\n",
        "    z = Embedding(MAX_WORDS, size, input_length=max_length, weights=[embedding_matrix], trainable=False)(z)\n",
        "  else:\n",
        "    z = Embedding(MAX_WORDS, size, input_length=max_length)(z)\n",
        "    \n",
        "  return z\n",
        "\n",
        "def add_rnn(z, size, bidirectional, cell_type, attention):\n",
        "  \"\"\"\n",
        "  This method adds the RNN layers to the network. It also adds an attention layer if intended.\n",
        "  \n",
        "  Returns the net with the RNN & Attention added.\n",
        "  \"\"\"\n",
        "  for i, rsz in enumerate(size):\n",
        "    if not bidirectional:\n",
        "      if i < len(size) - 1:\n",
        "        z = cell_type(rsz, return_sequences=True)(z)\n",
        "      else:\n",
        "        z = cell_type(rsz, return_sequences=attention)(z)\n",
        "    else:\n",
        "      if i < len(size) - 1:\n",
        "        z = Bidirectional(cell_type(rsz, return_sequences=True))(z)\n",
        "      else:\n",
        "        z = Bidirectional(cell_type(rsz, return_sequences=attention))(z)\n",
        "\n",
        "  if attention:\n",
        "    z = add_attention(z)\n",
        "    \n",
        "  return z\n",
        "\n",
        "def add_dnn(z, size, dropout, activation=\"sigmoid\"):\n",
        "  \"\"\"\n",
        "  This method adds the DNN layers to the network.\n",
        "  \n",
        "  Returns the net with the DNN layers added.\n",
        "  \"\"\"\n",
        "  for fsz in size:\n",
        "    if fsz is None:\n",
        "      return z\n",
        "\n",
        "    z = Dense(fsz, activation=activation)(z)\n",
        "    z = Dropout(dropout)(z)\n",
        "    \n",
        "  return z\n",
        "\n",
        "def add_attention(activations):\n",
        "  \"\"\"\n",
        "  This method adds an attention layer.\n",
        "  \n",
        "  Returns the model with the attention layer.\n",
        "  \"\"\"\n",
        "  \n",
        "  size =  K.int_shape(activations)[-1]\n",
        "  attention = BatchNormalization()(activations)\n",
        "  attention = Dense(1, activation='tanh')(attention)\n",
        "  attention = Flatten()(attention)\n",
        "  attention = Activation('softmax')(attention)\n",
        "  attention = RepeatVector(size)(attention)\n",
        "  attention = Permute([2, 1])(attention)\n",
        "  \n",
        "  z = Multiply()([activations, attention])\n",
        "  z = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(size,))(z)\n",
        "\n",
        "  return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oXEdPJGZsh_l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(params):\n",
        "  \"\"\"\n",
        "  This method creates a network model with the parameters given.\n",
        "  \n",
        "  Returns the uncompiled model.\n",
        "  \"\"\"\n",
        "  inputs = Input(name='inputs',shape=(params[\"max_length\"],))\n",
        "  \n",
        "  z = add_embeddings(inputs, params[\"load_embeddings\"], params[\"embeddings_size\"], params[\"embedding_matrix\"])\n",
        "  \n",
        "  z = add_rnn(z, params[\"rnn_size\"], params[\"bidirectional\"], params[\"cell_type\"], params[\"attention\"])\n",
        "  \n",
        "  z = add_dnn(z, params[\"dnn_size\"], params[\"dropout\"])\n",
        "  \n",
        "  outputs = Dense(params[\"num_classes\"], activation='sigmoid', name='output_layer')(z)\n",
        "  \n",
        "  net_model = Model(inputs=inputs,outputs=outputs)\n",
        "  \n",
        "  return net_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OICx8yDss53e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_models(network_parameters, verbose=False):\n",
        "  model_list = []\n",
        "  for net_p in network_parameters:\n",
        "    m = create_model(net_p)\n",
        "    m.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    model_list.append(m)\n",
        "    \n",
        "    if verbose:\n",
        "      m.summary()  \n",
        "      \n",
        "  return model_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iaz6AMV0TnRV",
        "colab_type": "code",
        "outputId": "d3e23cbd-b458-4f00-df97-539903ccd202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "cell_type": "code",
      "source": [
        "model_list = create_models(network_parameters, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 2336)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 2336, 300)         1304400   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               140160    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 13)                429       \n",
            "=================================================================\n",
            "Total params: 1,449,117\n",
            "Trainable params: 144,717\n",
            "Non-trainable params: 1,304,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1k_1Ff-iwRbV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TB Colab Callback\n",
        "We rewrite the tensorboardcolab callbacks to create different sessions depending on the variables our trainings have. This helps to differentiate the models in tensorboard."
      ]
    },
    {
      "metadata": {
        "id": "3jsRRzrFv1NH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "\n",
        "class TensorBoardColabCallback(TensorBoard):\n",
        "    def __init__(self, tbc=None, write_graph=True, name=None, **kwargs):\n",
        "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
        "\n",
        "        if tbc is None:\n",
        "            return\n",
        "\n",
        "        log_dir = tbc.get_graph_path()\n",
        "\n",
        "        training_log_dir = os.path.join(log_dir, 'training_{}'.format(name))\n",
        "        super(TensorBoardColabCallback, self).__init__(training_log_dir, **kwargs)\n",
        "\n",
        "        # Log the validation metrics to a separate subdirectory\n",
        "        self.val_log_dir = os.path.join(log_dir, 'validation_{}'.format(name))\n",
        "\n",
        "    def set_model(self, model):\n",
        "        # Setup writer for validation metrics\n",
        "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
        "        super(TensorBoardColabCallback, self).set_model(model)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Pop the validation logs and handle them separately with\n",
        "        # `self.val_writer`. Also rename the keys so that they can\n",
        "        # be plotted on the same figure with the training metrics\n",
        "        logs = logs or {}\n",
        "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
        "\n",
        "        for name, value in val_logs.items():\n",
        "            # print('val_logs:',epoch, name, value)\n",
        "            summary = tf.Summary()\n",
        "            summary_value = summary.value.add()\n",
        "            summary_value.simple_value = value.item()\n",
        "            summary_value.tag = name\n",
        "            self.val_writer.add_summary(summary, epoch)\n",
        "        self.val_writer.flush()\n",
        "\n",
        "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
        "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
        "        super(TensorBoardColabCallback, self).on_epoch_end(epoch, logs)\n",
        "        \n",
        "    def on_train_end(self, logs=None):\n",
        "        super(TensorBoardColabCallback, self).on_train_end(logs)\n",
        "        self.val_writer.close()\n",
        "\n",
        "tb.TensorBoardColabCallback = TensorBoardColabCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hd7YRWvKvXAj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def define_callbacks(name):\n",
        "  # Define the callbacks\n",
        "  tbc_callback = tb.TensorBoardColabCallback(tbc, name=name) # , histogram_freq=1)\n",
        "   \n",
        "  callbacks = [\n",
        "      ReduceLROnPlateau(),\n",
        "      EarlyStopping(patience=3),\n",
        "      tbc_callback\n",
        "  ]\n",
        "  return callbacks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5g5kvMmJgl3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create an array of names\n",
        "network_names = []\n",
        "for p in network_parameters:\n",
        "  name = \"tfid_load_embeddings_{}_num_classes_{}_embeddings_size_{}_rnn_size_{}_cell_type_{}_bidirectional_{}_attention_{}_dropout_{}_dnn_size_{}_batch_size_{}\".format(\n",
        "      p[\"load_embeddings\"], p[\"num_classes\"], p[\"embeddings_size\"], p[\"rnn_size\"], \n",
        "      str(p[\"cell_type\"]).split(\".\")[-1].replace(\"'\", \"\").replace(\">\", \"\"), p[\"bidirectional\"],\n",
        "      p[\"attention\"], p[\"dropout\"], p[\"dnn_size\"], p[\"batch_size\"])\n",
        "  name = name.replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"-\")\n",
        "  network_names.append(name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rQypOjW-Jz6v",
        "colab_type": "code",
        "outputId": "78e1608d-c075-4aea-e729-1441086060a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "for i, net_model in enumerate(model_list):\n",
        "  # Set a name for the model based on the tweaked parameters\n",
        "  p = network_parameters[i]\n",
        "  name = network_names[i]\n",
        "  model_path = SST_HOME+\"DL/models/\" + name\n",
        "\n",
        "  # If the model exists, don't compute it again.\n",
        "  # if os.path.isfile(model_path):\n",
        "  #   continue\n",
        "    \n",
        "  print(\"\\n\\n********************************************\\n\")    \n",
        "  print(name)\n",
        "  callbacks = define_callbacks(name)\n",
        "  # Fit the model and extract its data\n",
        "  history = net_model.fit(train_x_token, train_y, epochs=30, batch_size=network_parameters[i][\"batch_size\"], \n",
        "                          class_weight=class_weight, callbacks=callbacks,\n",
        "                          validation_split=0.25)\n",
        "      \n",
        "  # And save the model\n",
        "  net_model.save(model_path)\n",
        "  \n",
        "# To free memory from the gpu\n",
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "********************************************\n",
            "\n",
            "tfid_load_embeddings_True_num_classes_13_embeddings_size_300_rnn_size_64_cell_type_GRU_bidirectional_True_attention_False_dropout_0.3_dnn_size_32_batch_size_None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 151 samples, validate on 51 samples\n",
            "Epoch 1/30\n",
            "151/151 [==============================] - 43s 282ms/step - loss: 0.7461 - acc: 0.4738 - val_loss: 0.6891 - val_acc: 0.4555\n",
            "Epoch 2/30\n",
            "151/151 [==============================] - 42s 279ms/step - loss: 0.6880 - acc: 0.5487 - val_loss: 0.5502 - val_acc: 0.7315\n",
            "Epoch 3/30\n",
            "151/151 [==============================] - 42s 280ms/step - loss: 0.5509 - acc: 0.7096 - val_loss: 0.5057 - val_acc: 0.7300\n",
            "Epoch 4/30\n",
            "151/151 [==============================] - 42s 279ms/step - loss: 0.5261 - acc: 0.7269 - val_loss: 0.4961 - val_acc: 0.7511\n",
            "Epoch 5/30\n",
            "151/151 [==============================] - 41s 275ms/step - loss: 0.5166 - acc: 0.7331 - val_loss: 0.4872 - val_acc: 0.7722\n",
            "Epoch 6/30\n",
            "151/151 [==============================] - 42s 280ms/step - loss: 0.5101 - acc: 0.7371 - val_loss: 0.4804 - val_acc: 0.7722\n",
            "Epoch 7/30\n",
            "151/151 [==============================] - 41s 275ms/step - loss: 0.4995 - acc: 0.7412 - val_loss: 0.4750 - val_acc: 0.7738\n",
            "Epoch 8/30\n",
            "151/151 [==============================] - 42s 279ms/step - loss: 0.4960 - acc: 0.7580 - val_loss: 0.4692 - val_acc: 0.7738\n",
            "Epoch 9/30\n",
            "151/151 [==============================] - 42s 280ms/step - loss: 0.4970 - acc: 0.7514 - val_loss: 0.4656 - val_acc: 0.7738\n",
            "Epoch 10/30\n",
            "151/151 [==============================] - 42s 276ms/step - loss: 0.4909 - acc: 0.7570 - val_loss: 0.4610 - val_acc: 0.7738\n",
            "Epoch 11/30\n",
            "151/151 [==============================] - 42s 275ms/step - loss: 0.4799 - acc: 0.7545 - val_loss: 0.4569 - val_acc: 0.7738\n",
            "Epoch 12/30\n",
            "151/151 [==============================] - 42s 279ms/step - loss: 0.4909 - acc: 0.7397 - val_loss: 0.4538 - val_acc: 0.7738\n",
            "Epoch 13/30\n",
            "151/151 [==============================] - 42s 278ms/step - loss: 0.4823 - acc: 0.7514 - val_loss: 0.4508 - val_acc: 0.7738\n",
            "Epoch 14/30\n",
            "151/151 [==============================] - 41s 272ms/step - loss: 0.4825 - acc: 0.7545 - val_loss: 0.4485 - val_acc: 0.7738\n",
            "Epoch 15/30\n",
            "151/151 [==============================] - 43s 283ms/step - loss: 0.4803 - acc: 0.7621 - val_loss: 0.4461 - val_acc: 0.7738\n",
            "Epoch 16/30\n",
            "151/151 [==============================] - 43s 284ms/step - loss: 0.4696 - acc: 0.7575 - val_loss: 0.4439 - val_acc: 0.7738\n",
            "Epoch 17/30\n",
            "151/151 [==============================] - 42s 279ms/step - loss: 0.4635 - acc: 0.7682 - val_loss: 0.4424 - val_acc: 0.7738\n",
            "Epoch 18/30\n",
            " 64/151 [===========>..................] - ETA: 20s - loss: 0.4515 - acc: 0.7704"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7-Lz0JL11nmX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# SKLearn Predictions"
      ]
    },
    {
      "metadata": {
        "id": "8Lxy8qKkwD-1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "predictions_list = []\n",
        "for i, net_model in enumerate(model_list):\n",
        "  print(\"\\n\\n********************************************\\n\")\n",
        "  print(network_names[i])\n",
        "  model_path = SST_HOME+\"DL/models/\" + network_names[i]\n",
        "  try:\n",
        "    net_model = load_model(model_path)\n",
        "  except ValueError:\n",
        "    print(\"The model {} was not loaded correctly\".format(name))\n",
        "    continue\n",
        "    \n",
        "  predictions = net_model.predict(test_x_token)\n",
        "  predictions = np.array([[0 if value < 0.5 else 1 for value in prediction] for prediction in predictions])\n",
        "  predictions_list.append(predictions)\n",
        "  # measuring performance on test set\n",
        "  cr=classification_report(test_y, predictions, target_names=CATEGORIES.values)\n",
        "  print(cr)\n",
        "\n",
        "  # Release memory\n",
        "  K.clear_session()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1cCd5xkYqM3d"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#**Generating output in XML format**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UPDeSPwfqM3e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree\n",
        "import os\n",
        "NOT='not met'\n",
        "MET='met'\n",
        "\n",
        "#gets a idFile, a dictionary with the predictions (category, label) and the name of the classifier used.\n",
        "def outputToXML(idFile, dictPred, classifier):\n",
        "    \n",
        "    path=SST_HOME+'data/test/xml/'+idFile+'.xml'\n",
        "    output_dir = SST_HOME+'data/output/'+classifier\n",
        "    \n",
        "    output = output_dir+'/'+idFile+'.xml'\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "      print(\"\\n\\nmaking dir\")\n",
        "      s = os.makedirs(output_dir)\n",
        "      print(output_dir)\n",
        "      print(s)      \n",
        "   \n",
        "    et = xml.etree.ElementTree.parse(path)\n",
        "\n",
        "    new_tag = xml.etree.ElementTree.SubElement(et.getroot(), 'TAGS')\n",
        "    \n",
        "    for cat in dictPred.keys():\n",
        "        element = xml.etree.ElementTree.SubElement(new_tag, cat)    \n",
        "        if dictPred[cat]==0:\n",
        "            element.attrib['met'] = NOT \n",
        "        else:\n",
        "            element.attrib['met'] = MET\n",
        "\n",
        "    et.write(output)\n",
        "\n",
        "#function for creating a dictionary with the categories with values 0 or 1\n",
        "def iniDictPred(labels, categories):\n",
        "    \n",
        "    if len(labels)!=len(categories):\n",
        "        print('Warning!!!')\n",
        "        return None\n",
        "    \n",
        "    dictPred={}\n",
        "    i=0\n",
        "    \n",
        "    for x in categories:\n",
        "        dictPred[x]=labels[i]\n",
        "        i=i+1\n",
        "    return dictPred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3Ua3D6lQqM3f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#creates the output xml files per training\n",
        "\n",
        "for i, predictions in enumerate(predictions_list):\n",
        "  dictionary = zip(IDFILES, predictions)\n",
        "  for obj in dictionary:\n",
        "      idFile=str(obj[0][0])\n",
        "      labels=obj[1] #gets their predictions for this file\n",
        "      dictPred=iniDictPred(labels, CATEGORIES) #creates a dictionary to join categories and labels 0,1\n",
        "      outputToXML(idFile,dictPred,\"RNN/{}\".format(network_names[i]))\n",
        "\n",
        "  print('output xml files were generated!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IiigZnfNqM3m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "# Writes the output in a file for each training.\n",
        "for i, name in enumerate(network_names):\n",
        "  print(name) \n",
        "  path = \"data/output/RNN/\"\n",
        "  n = path + \"{}\".format(name)\n",
        "  os.system('cd \"{}\" && echo \"{}\" {} {}results.txt'.format(SST_HOME, name, \">\" if i == 0 else \">>\", path))\n",
        "  os.system('cd \"{}\" && python3 track1_eval.py data/test/gold {} >> {}results.txt'.format(SST_HOME, n, path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iyaCbNQri1Ri",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}